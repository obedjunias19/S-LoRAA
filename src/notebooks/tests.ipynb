{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1437000",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/multi-lora-agent/multi-lora-agent/src')\n",
    "\n",
    "\n",
    "from core.vllm_backend import VLLMBackend\n",
    "\n",
    "\n",
    "print(\"Testing VLLMBackend...\")\n",
    "\n",
    "# Initialize\n",
    "backend = VLLMBackend(\n",
    "    model_path=\"meta-llama/Llama-2-7b-hf\",\n",
    "    max_loras=4,\n",
    "    gpu_memory_utilization=0.8\n",
    ")\n",
    "\n",
    "# Test 1: Base model\n",
    "print(\"\\n Testing base model generation...\")\n",
    "outputs = backend.generate(\n",
    "    prompts=[\"The capital of France is\", \"Python is\"],\n",
    "    temperature=0.7,\n",
    "    max_tokens=20\n",
    ")\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"   Output {i+1}: {out}\")\n",
    "\n",
    "# Test 2: With SQL LoRA\n",
    "print(\"\\nTesting with SQL LoRA...\")\n",
    "sql_outputs = backend.generate(\n",
    "    prompts=[\"SELECT * FROM users WHERE age > 25\"],\n",
    "    lora_path=sql_lora_path,\n",
    "    lora_id=1,\n",
    "    temperature=0.1,\n",
    "    max_tokens=50\n",
    ")\n",
    "print(f\"   SQL Output: {sql_outputs[0]}\")\n",
    "\n",
    "# Test 3: Health check\n",
    "print(\"\\nHealth check...\")\n",
    "health = backend.health_check()\n",
    "print(f\"   Status: {'OK' if health else 'Failed'}\")\n",
    "\n",
    "print(\"\\nAll tests passed!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
